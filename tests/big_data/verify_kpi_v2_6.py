# tests/big_data/verify_kpi_v2_6_final_release.py
import os
import sys
import time
import re
import polars as pl
from scipy.stats import norm
import numpy as np
from pathlib import Path
from datetime import datetime

# ================= è·¯å¾‘ä¿®æ­£ =================
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '../../'))
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))
# ===========================================

# ================= è¨­å®š =================
DATA_DIR = os.path.join(current_dir, 'output', 'run_v2_6_dataset_20251212')
LOG_FILE = os.path.join(current_dir, 'logs', 'execution_history.log')

# ä¿®æ”¹å ±å‘Šè¼¸å‡ºè·¯å¾‘è‡³ docs è³‡æ–™å¤¾
DOCS_DIR = os.path.join(project_root, 'docs')
REPORT_FILE = os.path.join(DOCS_DIR, 'KPI_Validation_Report_v2_6.md')

# ç¢ºä¿ docs è³‡æ–™å¤¾å­˜åœ¨
if not os.path.exists(DOCS_DIR):
    os.makedirs(DOCS_DIR)
# =======================================

# æ¬„ä½å®šç¾©
UNTRAINABLE_COLS = [
    'physical_stamina', 'physical_strength', 'physical_speed', 'physical_jumping', 'physical_health',
    'offense_touch', 'offense_release', 
    'mental_off_iq', 'mental_def_iq', 'mental_luck'
]

TRAINABLE_COLS = [
    'offense_accuracy', 'offense_range', 
    'offense_passing', 'offense_dribble', 'offense_handle', 'offense_move',
    'defense_rebound', 'defense_boxout', 'defense_contest', 'defense_disrupt'
]

# ================= å·¥å…·é¡åˆ¥ï¼šé›™å‘è¼¸å‡º Logger =================
class ReportLogger(object):
    """å°‡ print å…§å®¹åŒæ™‚è¼¸å‡ºåˆ°çµ‚ç«¯æ©Ÿèˆ‡ Markdown æª”æ¡ˆ"""
    def __init__(self, filename):
        self.terminal = sys.stdout
        self.log = open(filename, "w", encoding="utf-8")
        
        # å¯«å…¥ Markdown æª”é ­
        header = f"# ASBL v2.6 Big Data Validation Report\n"
        header += f"> Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        header += "```text\n"
        self.log.write(header)

    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)

    def flush(self):
        self.terminal.flush()
        self.log.flush()
        
    def close(self):
        # å¯«å…¥ Markdown çµå°¾
        self.log.write("\n```\n")
        self.log.close()

# ================= æ ¼å¼åŒ–å‡½å¼ =================
def fmt_pct(count, total):
    """é€šç”¨æ ¼å¼åŒ–ï¼šè‹¥å°æ–¼ 0.01% ä¸”ä¸ç‚º 0ï¼Œé¡¯ç¤ºæ•¸é‡"""
    if total == 0: return "0.00%"
    pct = (count / total) * 100
    pct_str = f"{pct:6.4f}%"
    if pct < 0.01 and count > 0:
        return f"{pct_str} (n={count})"
    return pct_str

def fmt_matrix_cell(count, total, width=18):
    """çŸ©é™£è¡¨æ ¼å°ˆç”¨æ ¼å¼åŒ–"""
    if count == 0: return "0.0000%".rjust(width)
    pct = (count / total) * 100
    if pct < 0.01:
        s = f"{pct:.4f}% (n={int(count)})"
    else:
        s = f"{pct:.4f}%"
    return s.rjust(width)

def analyze_execution_log():
    """è§£æ Log æª”æ¡ˆç”¢ç”ŸåŸ·è¡Œå ±å‘Š"""
    print("ğŸ“Š [åŸ·è¡Œæ‘˜è¦å ±å‘Š] Execution Summary Report")
    print("-" * 100)
    
    if not os.path.exists(LOG_FILE):
        print(f"âš ï¸ æ‰¾ä¸åˆ° Log æª”: {LOG_FILE}ï¼Œè·³é Log åˆ†æã€‚")
        return

    try:
        with open(LOG_FILE, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        start_time = None
        end_time = None
        total_count = 0
        peak_ram = 0.0
        peak_cpu = 0.0
        
        for line in lines:
            if "[START" in line:
                parts = line.split(']')
                try:
                    start_time = datetime.strptime(parts[0].strip('['), "%Y-%m-%d %H:%M:%S")
                except: pass
            if "[COMPLETE" in line:
                parts = line.split(']')
                try:
                    end_time = datetime.strptime(parts[0].strip('['), "%Y-%m-%d %H:%M:%S")
                except: pass
                # è§£æ Count
                if "Count:" in line:
                    try:
                        total_count = int(line.split("Count:")[1].split("|")[0].strip())
                    except: pass
            
            # è§£æè³‡æºä½¿ç”¨
            if "RAM:" in line:
                try:
                    ram_str = line.split("RAM:")[1].split("GB")[0].strip()
                    peak_ram = max(peak_ram, float(ram_str))
                except: pass
            if "CPU:" in line:
                try:
                    cpu_str = line.split("CPU:")[1].split("%")[0].strip()
                    peak_cpu = max(peak_cpu, float(cpu_str))
                except: pass

        print(f"â€¢ Log æª”æ¡ˆ:      {LOG_FILE}")
        if start_time and end_time:
            duration = end_time - start_time
            total_seconds = duration.total_seconds()
            print(f"â€¢ åŸ·è¡Œæ™‚é–“:      {start_time} ~ {end_time}")
            print(f"â€¢ ç¸½è€—æ™‚:        {duration}")
            if total_count > 0:
                print(f"â€¢ ç¸½ç”Ÿæˆç­†æ•¸:    {total_count:,}")
                print(f"â€¢ å¹³å‡é€Ÿåº¦:      {total_count / total_seconds:.2f} ç­†/ç§’")
        
        print(f"â€¢ è¨˜æ†¶é«”å³°å€¼:    {peak_ram:.2f} GB")
        print(f"â€¢ CPU å³°å€¼:      {peak_cpu:.1f}%")
        print("-" * 100)
        print()

    except Exception as e:
        print(f"âš ï¸ Log è§£æå¤±æ•—: {e}")
        print("-" * 100)

def verify_kpi_final():
    # 0. é¡¯ç¤ºåŸ·è¡Œå ±å‘Š
    analyze_execution_log()

    print(f"ğŸš€ [ASBL v2.6] å•Ÿå‹•æœ€çµ‚ç‰ˆ KPI é©—æ”¶ç¨‹åº (Final Release)")
    print(f"ğŸ“‚ è³‡æ–™ä¾†æº: {DATA_DIR}")
    print("-" * 120)
    
    start_time = time.time()
    
    # 1. è¼‰å…¥è³‡æ–™
    try:
        lf = pl.scan_parquet(os.path.join(DATA_DIR, "*.parquet"))
        
        lf = lf.with_columns([
            # èº«é«˜å€é–“
            pl.when(pl.col("height") < 190).then(pl.lit("< 190"))
              .when((pl.col("height") >= 190) & (pl.col("height") <= 199)).then(pl.lit("190-199"))
              .when((pl.col("height") >= 200) & (pl.col("height") <= 209)).then(pl.lit("200-209"))
              .otherwise(pl.lit(">= 210")).alias("pos_height_bin"),
            
            # èº«é«˜åˆ‡ç‰‡
            (pl.col("height") // 10 * 10).cast(pl.Int32).alias("height_slice"),

            # å±¬æ€§ç¸½å’Œ
            pl.sum_horizontal(UNTRAINABLE_COLS).alias("untrainable_sum"),
            pl.sum_horizontal(TRAINABLE_COLS).alias("trainable_sum"),
            
            # æŠ€è¡“å±¬æ€§åˆ‡ç‰‡
            (pl.sum_horizontal(TRAINABLE_COLS) // 100 * 100).cast(pl.Int32).alias("trainable_slice")
        ])
        
        print("â³ æ­£åœ¨æƒæä¸¦èšåˆ 1 å„„ç­†è³‡æ–™ (é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜)...")
        df = lf.collect()
        
    except Exception as e:
        print(f"âŒ è®€å–å¤±æ•—: {e}")
        return

    total_count = len(df)
    print(f"âœ… è³‡æ–™è¼‰å…¥å®Œæˆ: {total_count:,} ç­† (è€—æ™‚ {time.time()-start_time:.2f}s)\n")

    # ==========================================
    # KPI 3.1 A: èº«é«˜åˆ†ä½ˆ (4ä½å°æ•¸)
    # ==========================================
    print("ğŸ“Š [KPI 3.1 A] èº«é«˜åˆ†ä½ˆèˆ‡æ¥µç«¯å€¼ç›£æ¸¬")
    print("   ç†è«–æ¨¡å‹: Mean=195, SD=10")
    print("-" * 120)
    
    height_dist = df.group_by('height_slice').len().sort('height_slice')
    height_dist = height_dist.with_columns((pl.col('len') / total_count).alias('actual_prob'))
    
    print(f"{'Slice (cm)':<12} | {'Actual %':<12} | {'Theory %':<12} | {'Diff %':<12} | {'Status'}")
    print("-" * 120)

    mean, std = 195, 10
    slices = range(160, 240, 10) 
    
    for s_start in slices:
        s_end = s_start + 10
        if s_start >= 230: continue 
        actual_row = height_dist.filter(pl.col('height_slice') == s_start)
        actual_prob = actual_row['actual_prob'][0] if not actual_row.is_empty() else 0.0
        prob_theory = norm(mean, std).cdf(s_end) - norm(mean, std).cdf(s_start)
        diff = actual_prob - prob_theory
        status = "âœ…" if abs(diff) < 0.015 else "âŒ" 
        print(f"{s_start}-{s_end-1}cm    | {actual_prob*100:>8.4f}%   | {prob_theory*100:>8.4f}%   | {diff*100:>+8.4f}%   | {status}")

    # æ¥µç«¯å€¼é€å…¬åˆ†è©³ç´°ç›£æ¸¬
    print("-" * 120)
    print("ğŸ” æ¥µç«¯å€¼é€å…¬åˆ†è©³ç´°ç›£æ¸¬ (Per cm Breakdown):")
    
    height_counts_df = df.group_by('height').len()
    h_map = dict(height_counts_df.iter_rows())

    def print_cm_detail(start, end, label):
        print(f"\n   >>> {label} ({start}-{end} cm)")
        print(f"   {'Height':<8} | {'Count':<10} | {'Actual %':<12} | {'Theory %':<12} | {'Diff %':<12}")
        print(f"   {'-'*70}")
        
        total_in_range = 0
        
        for h in range(start, end + 1):
            count = h_map.get(h, 0)
            total_in_range += count
            pct = count / total_count
            theory = norm(mean, std).cdf(h + 1) - norm(mean, std).cdf(h)
            diff = pct - theory
            print(f"   {h:<3} cm   | {count:>8,} | {pct*100:>9.4f}%  | {theory*100:>9.4f}%  | {diff*100:>+9.4f}%")
        
        print(f"   {'-'*70}")
        print(f"   Total    | {total_in_range:>8,} | {(total_in_range/total_count)*100:>9.4f}%")

    print_cm_detail(160, 169, "Low Extreme")
    print_cm_detail(221, 230, "High Extreme")

    # ==========================================
    # KPI 3.1 B: ä½ç½®åˆ¤å®š (4ä½å°æ•¸)
    # ==========================================
    print("\nğŸ“Š [KPI 3.1 B] ä½ç½®åˆ¤å®šçŸ©é™£ (Position Assignment)")
    print(f"{'Height Bin':<10} | {'Pos':<4} | {'Target %':<10} | {'Actual %':<22} | {'Diff %':<10} | {'Check'}")
    print("-" * 120)
    
    bin_counts = df['pos_height_bin'].value_counts()
    bin_map = {r['pos_height_bin']: r['count'] for r in bin_counts.to_dicts()}
    pos_counts = df.group_by(['pos_height_bin', 'position']).len()
    
    specs = [
        ('< 190', {'PG': 60, 'SG': 40}),
        ('190-199', {'PG': 35, 'SG': 45, 'SF': 20}),
        ('200-209', {'PF': 50, 'SF': 20, 'C': 15, 'SG': 10, 'PG': 5}),
        ('>= 210', {'C': 45, 'PF': 30, 'SF': 10, 'SG': 10, 'PG': 5}),
    ]
    
    for h_bin, targets in specs:
        bin_total = bin_map.get(h_bin, 0)
        if bin_total == 0: continue
        print(f"[{h_bin}] (Total: {bin_total:,})")
        for pos, target_pct in targets.items():
            actual_row = pos_counts.filter((pl.col('pos_height_bin') == h_bin) & (pl.col('position') == pos))
            actual_count = actual_row['len'][0] if not actual_row.is_empty() else 0
            actual_pct = (actual_count / bin_total) * 100
            diff = actual_pct - target_pct
            status = "âœ…" if abs(diff) < 1.0 else "âŒ"
            
            actual_str = f"{actual_pct:>8.4f}% ({actual_count})"
            print(f"{'':<10} | {pos:<4} | {target_pct:>8.4f}% | {actual_str:<22} | {diff:>+8.4f}% | {status}")
        print("-" * 120)

    # ==========================================
    # KPI 3.3: å¤©è³¦ç”Ÿæˆè©³ç´°é©—è­‰ (æ•´æ•¸é¡¯ç¤º)
    # ==========================================
    print("\nğŸ“Š [KPI 3.3] å¤©è³¦ç”Ÿæˆè©³ç´°é©—è­‰ (Untrainable Stats)")
    print("-" * 120)
    
    print("ğŸ” (A) ç¸½åˆ†å€é–“åˆè¦æ€§ (Total Sum Check):")
    untrainable_specs = {
        'G': (10, 400), 'C': (399, 600), 'B': (599, 700),
        'A': (699, 800), 'S': (799, 900), 'SS': (900, 950), 'SSR': (951, 990)
    }
    u_stats = df.group_by('grade').agg([
        pl.col('untrainable_sum').min().alias('min'),
        pl.col('untrainable_sum').max().alias('max'),
        pl.col('untrainable_sum').mean().alias('avg')
    ]).to_pandas().set_index('grade')
    
    print(f"{'Grade':<6} | {'Spec Range':<15} | {'Actual Range':<15} | {'Avg':<6} | {'Status'}")
    for g in ['G', 'C', 'B', 'A', 'S', 'SS', 'SSR']:
        spec_min, spec_max = untrainable_specs[g]
        row = u_stats.loc[g]
        status = "âœ…"
        if row['min'] < spec_min or row['max'] > spec_max:
            status = f"âŒ (Violated)"
        print(f"{g:<6} | {spec_min}-{spec_max:<15} | {int(row['min'])}-{int(row['max']):<15} | {int(row['avg']):<6} | {status}")

    # ==========================================
    # KPI 3.3 B: å–®é …æ¥µå€¼åˆ†ä½ˆ
    # ==========================================
    print("\nğŸ” (B) å–®é …å±¬æ€§å…¨é‡åˆ†ä½ˆ (Full Stat Distribution):")
    print("   ç›®æ¨™: é©—è­‰æ‰€æœ‰ 20 å€‹å±¬æ€§æ˜¯å¦å‡å‹»åˆ†ä½ˆã€‚")
    print(f"{'Stat Name':<20} | {'1-10':<15} | {'11-40':<15} | {'41-60':<15} | {'61-89':<15} | {'90-99':<15}")
    print("-" * 120)
    
    all_stats_cols = UNTRAINABLE_COLS + TRAINABLE_COLS
    for col in all_stats_cols:
        counts = df.select([
            pl.col(col).filter((pl.col(col) >= 1) & (pl.col(col) <= 10)).len().alias('c1'),
            pl.col(col).filter((pl.col(col) >= 11) & (pl.col(col) <= 40)).len().alias('c2'),
            pl.col(col).filter((pl.col(col) >= 41) & (pl.col(col) <= 60)).len().alias('c3'),
            pl.col(col).filter((pl.col(col) >= 61) & (pl.col(col) <= 89)).len().alias('c4'),
            pl.col(col).filter((pl.col(col) >= 90) & (pl.col(col) <= 99)).len().alias('c5')
        ]).to_dicts()[0]
        
        print(f"{col:<20} | {fmt_pct(counts['c1'], total_count):<15} | {fmt_pct(counts['c2'], total_count):<15} | {fmt_pct(counts['c3'], total_count):<15} | {fmt_pct(counts['c4'], total_count):<15} | {fmt_pct(counts['c5'], total_count):<15}")

    # ==========================================
    # KPI 3.4: æŠ€è¡“ç”Ÿæˆé©—è­‰
    # ==========================================
    print("\nğŸ“Š [KPI 3.4] æŠ€è¡“ç”Ÿæˆé©—è­‰ (Trainable Stats)")
    print("-" * 120)
    
    caps = {'G': 800, 'C': 700, 'B': 650, 'A': 600, 'S': 550, 'SS': 550, 'SSR': 550}
    
    print("ğŸ” (A) åˆ‡ç‰‡åˆ†ä½ˆ (æ¯ 100 åˆ†):")
    slice_matrix = df.group_by(['grade', 'trainable_slice']).len()
    grade_totals = df.group_by('grade').len().rename({'len': 'g_total'})
    
    slice_pivot_count = slice_matrix.to_pandas().pivot(index='grade', columns='trainable_slice', values='len').fillna(0)
    cols = sorted(slice_pivot_count.columns)
    slice_pivot_count = slice_pivot_count[cols]
    slice_pivot_count = slice_pivot_count.reindex(['G', 'C', 'B', 'A', 'S', 'SS', 'SSR'])
    
    g_total_map = {row['grade']: row['g_total'] for row in grade_totals.to_dicts()}
    
    col_width = 18
    header = "Grade  | " + " | ".join([f"{c}-{c+99}".center(col_width) for c in cols])
    print(header)
    print("-" * len(header))
    
    for g, row in slice_pivot_count.iterrows():
        g_total = g_total_map.get(g, 0)
        vals_str = []
        for count in row:
            vals_str.append(fmt_matrix_cell(count, g_total, width=col_width))
        print(f"{g:<6} | {' | '.join(vals_str)}")

    print("\nğŸ” (B) æ¥µå€¼ç›£æ¸¬ (Extreme Values):")
    print(f"{'Grade':<6} | {'Cap':<5} | {'Trash (<100)':<20} | {'Elite (>Cap-50)':<20} | {'Max Val':<8}")
    print("-" * 120)
    
    t_stats = df.group_by('grade').agg([
        pl.col('trainable_sum').max().alias('max_val'),
        pl.col('trainable_sum').filter(pl.col('trainable_sum') < 100).len().alias('trash_cnt'),
    ]).to_pandas().set_index('grade')
    
    for g in ['G', 'C', 'B', 'A', 'S', 'SS', 'SSR']:
        cap = caps[g]
        row = t_stats.loc[g]
        g_total = g_total_map.get(g, 0)
        elite_cnt = len(df.filter((pl.col('grade') == g) & (pl.col('trainable_sum') > cap - 50)))
        
        print(f"{g:<6} | {cap:<5} | {fmt_pct(row['trash_cnt'], g_total):<20} | {fmt_pct(elite_cnt, g_total):<20} | {row['max_val']:<8}")

    # ==========================================
    # KPI 3.5: å¹´é½¡åˆ†ä½ˆ (ç§»å‹•è‡³æ­¤)
    # ==========================================
    print("\nğŸ“Š [KPI 3.5] å¹´é½¡åˆ†ä½ˆé©—è­‰ (Age Distribution)")
    print("   è¦å‰‡: SSR=18(100%), SS=18-19(50%), S=18-20, A=18-21, B=18-22, C=18-23, G=18-24")
    print(f"{'Grade':<6} | {'Age Range':<10} | {'Target %':<10} | {'Check'}")
    print("-" * 120)

    age_rules = {
        'SSR': (18, 18), 'SS': (18, 19), 'S': (18, 20),
        'A': (18, 21), 'B': (18, 22), 'C': (18, 23), 'G': (18, 24)
    }

    for g, (min_a, max_a) in age_rules.items():
        g_total = len(df.filter(pl.col('grade') == g))
        if g_total == 0: continue

        num_choices = max_a - min_a + 1
        target_pct = 100.0 / num_choices
        
        outliers = len(df.filter((pl.col('grade') == g) & ((pl.col('age') < min_a) | (pl.col('age') > max_a))))
        
        is_uniform = True
        dist_lines = []
        for age in range(min_a, max_a + 1):
            cnt = len(df.filter((pl.col('grade') == g) & (pl.col('age') == age)))
            pct = (cnt / g_total) * 100
            dist_lines.append(f"       â†³ {age}æ­²: {pct:.4f}%")
            if abs(pct - target_pct) > 3.0:
                is_uniform = False
        
        status = "âœ…" if is_uniform and outliers == 0 else "âŒ"
        if outliers > 0: status += f" ({outliers} ç•°å¸¸)"

        print(f"{g:<6} | {min_a}-{max_a:<10} | ~{target_pct:.4f}%   | {status}")
        for line in dist_lines:
            print(line)
        print("-" * 60)

    # ==========================================
    # KPI 3.6: é•è¦èˆ‡ç•°å¸¸æª¢æ¸¬ (é †å»¶è‡³æ­¤)
    # ==========================================
    print("\nğŸš¨ [KPI 3.6] é•è¦èˆ‡ç•°å¸¸æª¢æ¸¬ (Violation Check)")
    print("   ç›®æ¨™: ç¢ºä¿æ²’æœ‰ä»»ä½•ä¸€ç­†è³‡æ–™é•åç¡¬æ€§è¦å‰‡ã€‚")
    print("-" * 120)
    
    violations = []
    
    for g, cap in caps.items():
        violation_cnt = len(df.filter((pl.col('grade') == g) & (pl.col('trainable_sum') > cap)))
        if violation_cnt > 0:
            violations.append(f"âŒ [æŠ€è¡“å±¬æ€§ä¸Šé™] ç­‰ç´š {g} æœ‰ {violation_cnt} åçƒå“¡è¶…éä¸Šé™ {cap}!")
        else:
            print(f"âœ… [æŠ€è¡“å±¬æ€§ä¸Šé™] ç­‰ç´š {g}: ç„¡é•è¦ (æœ€å¤§å€¼ <= {cap})")

    for g, (u_min, u_max) in untrainable_specs.items():
        violation_cnt = len(df.filter((pl.col('grade') == g) & ((pl.col('untrainable_sum') < u_min) | (pl.col('untrainable_sum') > u_max))))
        if violation_cnt > 0:
            violations.append(f"âŒ [å¤©è³¦å±¬æ€§ç¸½å’Œå€é–“] ç­‰ç´š {g} æœ‰ {violation_cnt} åçƒå“¡è¶…å‡ºå€é–“ {u_min}-{u_max}!")
        else:
            print(f"âœ… [å¤©è³¦å±¬æ€§ç¸½å’Œå€é–“] ç­‰ç´š {g}: ç„¡é•è¦")

    for col in all_stats_cols:
        out_of_bound = len(df.filter((pl.col(col) < 1) | (pl.col(col) > 99)))
        if out_of_bound > 0:
            violations.append(f"âŒ [å–®é …å±¬æ€§é‚Šç•Œ] æ¬„ä½ {col} æœ‰ {out_of_bound} å€‹æ•¸å€¼è¶…å‡º 1-99 ç¯„åœ!")
    
    if not violations:
        # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¢ºçš„è®Šæ•¸åç¨± all_stats_cols
        print(f"âœ… [å–®é …å±¬æ€§é‚Šç•Œ] æ‰€æœ‰ {len(all_stats_cols)} å€‹å±¬æ€§çš†åœ¨ 1-99 ç¯„åœå…§ã€‚")
    
    print("-" * 120)
    if len(violations) == 0:
        print("ğŸ‰ å®Œç¾ï¼1 å„„ç­†è³‡æ–™å…¨éƒ¨é€šéç¡¬æ€§è¦å‰‡æª¢æŸ¥ã€‚")
    else:
        print(f"âš ï¸ ç™¼ç¾ {len(violations)} é …é•è¦ï¼š")
        for v in violations:
            print(v)

if __name__ == "__main__":
    try:
        from scripts.terminal import clear_terminal
        clear_terminal()
    except ImportError:
        pass
    except Exception:
        pass
    
    # å•Ÿå‹•é›™å‘ Logger
    original_stdout = sys.stdout
    logger = ReportLogger(REPORT_FILE)
    sys.stdout = logger
    
    try:
        verify_kpi_final()
    finally:
        # æ¢å¾© stdout ä¸¦é—œé–‰æª”æ¡ˆ
        sys.stdout = original_stdout
        logger.close()
        print(f"\nğŸ“„ å ±å‘Šå·²ç”Ÿæˆ: {REPORT_FILE}")
